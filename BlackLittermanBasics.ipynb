{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a804c198",
   "metadata": {},
   "source": [
    "#  A python implementation of the Black Litterman model on the S&P 500 index\n",
    "\n",
    "###  There are 2 aspects one needs to understand about the Black Litterman model.First one is the statistical structure of the model, and the other is how this statistical proceedure is implemented in formulating the optimal weights of assets in which to invest. Below follows a (very) brief look into the mathematics of the model.\n",
    "\n",
    "#### Notation:\n",
    "#### i) We denote the prior by $f(θ)$. The statistical model (sometimes referred to as the \\\"likelihood\\\" in certain bayesian inference texts)  by $ f(x|θ)$, and the posterior by $f(θ|x)$\n",
    "#### The predictive distribution of future returns is denoted by $f(y|x)$\n",
    "#### ii) We can derive the posterior by $ f(θ|x)= \\frac{f(x|θ)f(θ)}{\\int f(x|θ)f(θ)dθ} $\n",
    "#### iii) It is assumed that the prior distribution and the likelihood, are normally distributed with the following means and variances:\n",
    "### $f(θ)=φ(θ;m,s^2) , f(x|θ)=φ(x;θ,σ_ο^2)$\n",
    "#### Then it can be shown through straightforward calculations that the posterior also follows a normal distribution:\n",
    "### $ f(θ|x)= φ(θ; \\tilde{m}, \\tilde{s}^2)$ where $\\tilde{m}=\\frac{\\frac{m}{s^2}+\\frac{x}{σ_ο^2}}{\\frac{1}{s^2}+\\frac{1}{σ_ο^2}}$ and $\\tilde{s}^2= \\frac{1}{\\frac{1}{s^2}+\\frac{1}{σ_ο^2}} $\n",
    "#### It should be pointed out that the precisions are additive, and that the posterior mean is a precision weighted average of the prior and statistical model means \n",
    "#### iv) The predictive distribution $f(y|x)$ can be derived as follows:\n",
    "####  It is known  that $f(x,y|θ)= f(y|x,θ)f(x|θ)$\n",
    "#### In order to compute the joint density of $x$ and $y$ we notice that $f(x,y)= \\int f(x,y|θ)f(θ)dθ$\n",
    "##### (we condition on another variable,and later intergrate over all possible values of that variable)\n",
    "#### combining the results above we get:\n",
    "### $f(y|x)=\\frac{f(x,y)}{f(x)} \\implies f(y|x)= \\frac{\\int f(x,y|θ)f(θ)dθ}{f(x)} \\implies f(y|x)=\\frac{\\int f(y|x,θ)f(x|θ)f(θ)dθ}{f(x)} \\implies         f(y|x)= \\int f(y|x,θ)f(θ|x)dθ$\n",
    "####  $f(y|x)$ is used for the predictive distribution instead of $f(y|x,θ)$ which one might think is more intuitive. Reason being we have observed $x$, but not $θ$ . Hence we are averaging over all the possible values of $θ$, with weights of $θ$ being distributed according to the posterior distribution.\n",
    "#### It can be shown that that $f(y|x)$ is also normally distributed with mean $\\tilde{m}$ and variance $ σ_ο^2 + \\tilde{s}^2$\n",
    "#### The predictive distribution has the same mean as the posterior distribution, but an increased variance, to account for the variance of estimation of $θ$, along with the asset's true variance\n",
    "\n",
    "#### An investor's goal is to maximize the expected value of a utility function who's inputs are a vector of optimal porftolio weights, a vector of excess returns over the benchmark, a covariance matrix and a constant representing risk aversion. One can choose from a variety of utility functions including linear, logarithmic, exponential, however we will use a quadratic as is the standard practice with mean variance preferences. W is used to denote the vector of optimal weights.\n",
    "\n",
    "###  $ U(w)= w^Tθ - \\frac{λw^TΣw}{2} $\n",
    "\n",
    "### Next we focus into how we can incorporate the model into an investment decision making process\n",
    "\n",
    "## NOTE: As of 2023, most of the code is outdated, as some libraries like pandas_datareader don't work anymore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import wikipedia as wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "html=wp.page(\"List_of_S%26P_500_companies\").html().encode(\"UTF-8\")\n",
    "dfwiki=pd.read_html(html)\n",
    "WikiTickers=list(dfwiki[0]['Symbol'])\n",
    "Tickers=[x.replace(\".\",'-') for x in WikiTickers] #yahoo finance uses \"-\", wiki uses\".\"\n",
    "\n",
    "start=datetime.date(2022,12,16)\n",
    "end=datetime.date.today()-datetime.timedelta(days=1)\n",
    "\n",
    "df=yf.download(Tickers,start,end)\n",
    "prices=df['Adj Close']\n",
    "returns=np.log(prices/prices.shift(1)).dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517668cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=returns.cov().to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dc139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data\n",
    "marketcap=data.get_quote_yahoo(Tickers)['marketCap']\n",
    "weights=marketcap.values/marketcap.values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33cf431",
   "metadata": {},
   "source": [
    "#### a) The prior distribution represents our belief in the efficiency of the market. We assume that the market is in equilibrium, and so the vector theta of expected excess returns is the one implied by the maximization of the utility function.For an approximation to the market portfolio the S&P 500 index is used. For the covariance matrix $Σ$ we compute the historical returns of the S&P500 over a certain time period, and set the risk aversion constant $λ$ equal to 4. The weights in each stock are computed by dividing the market capitalization of each stock with the total market capitalization of the portfolio.\n",
    "\n",
    "#### b) The likelihood,or statistical model, represents our view.If, for example, our view is that \\\"Apple stock will outperform Tesla by 5%\\\", we create a $p$ vector ([0000......1........00000....-1...000]). Zero weights everywhere, 100% weight in Apple stock, -100% in Tesla stock, and then state that as $pθ=q$\n",
    "\n",
    "#### c) The posterior mean and variance are denoted by 'thetabl' and 'sigmabl' and are calculated exactly as discussed earlier in the mathematical analysis part. Same thing goes for the variance of the predictive distribution 'sigmapred'. The vector of expected excess returns $θ$ of the predictive distribution,is of course, the posterior or black litterman $θ$\n",
    "\n",
    "\n",
    "### Note: the code below could be purely functional, as it currently stands there is no need for a class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ef31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackLitterman:\n",
    "    def __init_(self,sigma,weights,tau,l,p,q):\n",
    "        self.sigma=sigma\n",
    "        self.weights=weights #benchmark weights\n",
    "        self.tau=tau\n",
    "        self.l=l\n",
    "        self.p=p   #weights of our views\n",
    "        self.q=q\n",
    "        \n",
    "        \n",
    "        def calc(self):\n",
    "            self.thetaimplied= self.sigma@self.weight*self.l\n",
    "            self.omega=self.tau*self.p.T@self.sigma@self.p\n",
    "            self.sigmabl=np.linalg.inv(np.linalg.inv(self.tau*self.sigma)+self.p@np.linalg.inv(self.omega)@self.p.T)\n",
    "            self.thetabl= self.sigmabl@(np.linalg.inv(self.tau*self.sigma)@thetaimplied+self.p@np.linalg.inv(self.omega)*self.q)\n",
    "            self.sigmapred= self.sigma + self.sigmabl\n",
    "            self.predoptimal= 1/l*np.linalg.inv(self.sigmapred)@self.thetabl\n",
    "            self.bloptimal=1/l*np.linalg.inv(self.sigma)@self.thetabl\n",
    "            self.naiveoptimal= 1/l*self.q/(self.p.T@self.sigma@self.p)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f70ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume our view is \\\"Apple will outperform Tesla by 5%\n",
    "p=np.zeros((505,1))     #create the vector of weights of our view as explained beforehand\n",
    "p[Tickers.index('AAPL')]=1\n",
    "p[Tickers.index('TSLA')]=-1\n",
    "q=0.05\n",
    "tau=1/5  #usually choose tau as 1 over T, where T= amount of years used in computing the historical covariance matrix Σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= BlackLitterman(sigma,weights.reshape(505,1),tau,4,p,q)\n",
    "model.calc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5325f",
   "metadata": {},
   "source": [
    "#### Some things worth noting:\n",
    "\n",
    "#### i)Black Litterman optimal weights  are given by the vector $θ$ of the posterior distribution and $Σ$ the historical covariance matrix.Black and Litterman choose to ignore parameter uncertainty. It is somewhat justifiable as the parameter uncertainty tends to be smaller than the inherent underlying risk.This is  how it is generally used by practitioners in the industry. While it becomes apparent that the method can no longer be considered purely Bayesian, Black and Litterman themselves never referred to it as such. What best fits their approach is \\\"Theil's method of mixed estimation\\\". For any reader that might be intrested, further information can be found here: http://sims.princeton.edu/yftp/DummyObs/DumObsPriorSlides.pdf\n",
    "\n",
    "#### ii) Predictive optimal weights  are computed by the same $θ$ as the posterior, the only difference being that the covariance matrix used, also accounts for parameter uncertainty, adding the estimation error to the asset risk.This is closer to a \\\"pure\\\"  Bayesian approach.\n",
    "\n",
    "#### iii) The reader might have noticed that \\\"naive optimal\\\" returns a scalar instead a vector which we would expect,since we want to compute the updated weights of the S&P 500 portfolio. It is meant to be multiplied by the weights of our views $p$ forming a long short portfolio,and then added to the benchmark to create the optimal naive portfolio. More information can be found at \\\"The Black Litterman Formula\\\" by Colm O'Cinneide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c4707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
